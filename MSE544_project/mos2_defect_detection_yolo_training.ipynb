{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4be7fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r yolov5/requirements.txt --user \n",
    "#%pip install scikit-learn scikit-image azureml-core --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35125bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import labeledImage, normalize_coordinates, convert_to_yolo_format\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os, shutil, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f63b195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the root folder that contains images and labels\n",
    "\n",
    "path_to_final_project = r'final_project_data'\n",
    "\n",
    "source_images_dir = f'{path_to_final_project}/mos2/'\n",
    "source_labels_dir = f'{path_to_final_project}/mos2/labels/'\n",
    "\n",
    "labeled_images = []\n",
    "tag = 'mos2' \n",
    "\n",
    "for file in os.listdir(source_images_dir):\n",
    "    # find all jpeg file and it's ImageJ label\n",
    "    if file.endswith(\".jpeg\"):\n",
    "        image_path = os.path.join(source_images_dir, file)\n",
    "        label_path = os.path.join(source_labels_dir, file.split('.')[0] + '.txt')\n",
    "        labeled_images.append(labeledImage(image_path))\n",
    "        labeled_images[-1].add_labels_from_file(tag, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc14b970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 6, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_val_set, test_set = train_test_split(labeled_images, test_size=0.1)\n",
    "train_set, val_set = train_test_split(train_and_val_set, test_size=(2/9))\n",
    "\n",
    "len(train_set), len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bccbf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the molecule_images directory if it doesn't exist\n",
    "output_dir = os.path.join(os.getcwd(),'mos2_images')\n",
    "if not os.path.exists(output_dir): os.mkdir(output_dir)\n",
    "\n",
    "train_dir = os.path.join(output_dir, 'train') \n",
    "val_dir   = os.path.join(output_dir, 'val') \n",
    "test_dir  = os.path.join(output_dir, 'test') \n",
    "\n",
    "# Create the sub-directories\n",
    "for d in [train_dir, val_dir, test_dir]:\n",
    "    if not os.path.exists(d): os.mkdir(d)\n",
    "    \n",
    "    images_sub_dir = os.path.join(d, 'images')\n",
    "    labels_sub_dir = os.path.join(d, 'labels')\n",
    "    \n",
    "    for sub_dir in [images_sub_dir, labels_sub_dir]:\n",
    "        if not os.path.exists(sub_dir): os.mkdir(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c935cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated labels for image  4.jpeg\n",
      "successfully generated labels for image  8.jpeg\n",
      "successfully generated labels for image  11.jpeg\n",
      "successfully generated labels for image  20.jpeg\n",
      "successfully generated labels for image  22.jpeg\n",
      "successfully generated labels for image  7.jpeg\n",
      "successfully generated labels for image  26.jpeg\n",
      "successfully generated labels for image  1.jpeg\n",
      "successfully generated labels for image  18.jpeg\n",
      "successfully generated labels for image  14.jpeg\n",
      "successfully generated labels for image  5.jpeg\n",
      "successfully generated labels for image  10.jpeg\n",
      "successfully generated labels for image  12.jpeg\n",
      "successfully generated labels for image  28.jpeg\n",
      "successfully generated labels for image  15.jpeg\n",
      "successfully generated labels for image  27.jpeg\n",
      "successfully generated labels for image  17.jpeg\n",
      "successfully generated labels for image  9.jpeg\n",
      "successfully generated labels for image  2.jpeg\n",
      "successfully generated labels for image  16.jpeg\n",
      "successfully generated labels for image  24.jpeg\n",
      "successfully generated labels for image  25.jpeg\n",
      "successfully generated labels for image  3.jpeg\n",
      "successfully generated labels for image  19.jpeg\n",
      "successfully generated labels for image  23.jpeg\n",
      "successfully generated labels for image  13.jpeg\n",
      "successfully generated labels for image  21.jpeg\n",
      "successfully generated labels for image  6.jpeg\n"
     ]
    }
   ],
   "source": [
    "# make unified yolo tags \n",
    "tags = [tag]\n",
    "\n",
    "# zip the dataset\n",
    "dataset = [(train_dir, train_set),(val_dir, val_set),(test_dir, test_set)]\n",
    "\n",
    "for d, s in dataset:\n",
    "    images_sub_dir = os.path.join(d, 'images')\n",
    "    labels_sub_dir = os.path.join(d, 'labels')\n",
    "\n",
    "    # copy over the images\n",
    "    for img in s:\n",
    "        shutil.copyfile(img.path, os.path.join(images_sub_dir, img.name))\n",
    "    \n",
    "    # covert ImageJ labels to yolo format and save it to labels_sub_dir\n",
    "    convert_to_yolo_format(s, labels_sub_dir, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdf675ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate yolo yaml file\n",
    "yolo_yaml = os.path.join(output_dir, 'mos2_defect_detection_yolov5.yaml')\n",
    "\n",
    "with open(yolo_yaml, 'w') as yamlout:\n",
    "    yaml.dump(\n",
    "        {'train': train_dir,\n",
    "         'val': val_dir,\n",
    "         'nc': len(tags),\n",
    "         'names': tags},\n",
    "        yamlout,\n",
    "        default_flow_style=None,\n",
    "        sort_keys=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab7944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/weights/yolov5s.pt, cfg=, data=./mos2_images/mos2_defect_detection_yolov5.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=1, batch_size=5, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5/data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=./runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "YOLOv5 ðŸš€ v7.0-419-gcd44191c Python-3.9.21 torch-2.7.0+cu126 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5/weights/yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005078125), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/zbyw/MSE544_project/mos2_images/train/labels.cache... 19 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/zbyw/MSE544_project/mos2_images/val/labels.cache... 6 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<?, ?it/s]\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.28 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Plotting labels to runs/train/exp10/labels.jpg... \n",
      "/home/zbyw/MSE544_project/yolov5/train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 5 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp10\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]/home/zbyw/MSE544_project/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "        0/0         0G     0.1279     0.2056          0        312        640:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:16<00:49, 16.39s/it]/home/zbyw/MSE544_project/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "        0/0         0G     0.1273     0.2002          0        273        640:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:26<00:24, 12.42s/it]/home/zbyw/MSE544_project/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "        0/0         0G     0.1257     0.1783          0        150        640:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:32<00:09,  9.76s/it]/home/zbyw/MSE544_project/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "        0/0         0G     0.1249     0.1841          0        189        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:37<00:00,  9.41s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 0.800s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.29s/it]\n",
      "                   all          6        268          0          0          0          0\n",
      "\n",
      "1 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from runs/train/exp10/weights/last.pt, 14.4MB\n",
      "Optimizer stripped from runs/train/exp10/weights/best.pt, 14.4MB\n",
      "\n",
      "Validating runs/train/exp10/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 0.800s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.09s/it]\n",
      "                   all          6        268          0          0          0          0\n",
      "Results saved to \u001b[1mruns/train/exp10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run YOLOv5 training with pretrained weights\n",
    "# YOLOv5 will download weights if not found\n",
    "%run yolov5/train.py --img 640 --batch 5 --epochs 1 --data ./mos2_images/mos2_defect_detection_yolov5.yaml --weights yolov5/weights/yolov5s.pt --project ./runs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edf8b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment, ScriptRunConfig\n",
    "from azureml.core.conda_dependencies import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d83c30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5_env = Environment(name=\"yolov5_env\")\n",
    "\n",
    "# Start from a base docker environments defined by Microsoft\n",
    "yolov5_env.docker.base_image  = \"docker.io/hstirrat/yolov5-env:fixed\"\n",
    "\n",
    "conda_dep = CondaDependencies()\n",
    "# Indicate which version of python needs to be installed\n",
    "conda_dep.add_conda_package('python=3.9')\n",
    "\n",
    "# install all the yolov5 requirement at the image build time\n",
    "with open('./yolov5/requirements.txt', 'r') as f:\n",
    "    line = f.readline()\n",
    "    \n",
    "    while line != '':    \n",
    "        # If the line is a comment or empty, skip it    \n",
    "        if line.startswith('#') or len(line.split()) == 0:\n",
    "            line = f.readline()\n",
    "            continue\n",
    "        # Otherwise add the corresponding package name as a dependency\n",
    "        conda_dep.add_pip_package(line.split()[0])\n",
    "        # Then move on to the next line in the requirements.txt file\n",
    "        line = f.readline()\n",
    "\n",
    "yolov5_env.python.conda_dependencies=conda_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e18a61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Environment.get_image_details of {\n",
       "    \"assetId\": null,\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"docker.io/hstirrat/yolov5-env:fixed\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": \"2g\"\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"yolov5_env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.9\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"gitpython>=3.1.30\",\n",
       "                        \"matplotlib>=3.3\",\n",
       "                        \"numpy>=1.23.5\",\n",
       "                        \"opencv-python>=4.1.1\",\n",
       "                        \"pillow>=10.3.0\",\n",
       "                        \"psutil\",\n",
       "                        \"PyYAML>=5.3.1\",\n",
       "                        \"requests>=2.32.2\",\n",
       "                        \"scipy>=1.4.1\",\n",
       "                        \"thop>=0.1.1\",\n",
       "                        \"torch>=1.8.0\",\n",
       "                        \"torchvision>=0.9.0\",\n",
       "                        \"tqdm>=4.66.3\",\n",
       "                        \"ultralytics>=8.2.34\",\n",
       "                        \"pandas>=1.1.4\",\n",
       "                        \"seaborn>=0.11.0\",\n",
       "                        \"setuptools>=70.0.0\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": null\n",
       "}>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolov5_env.get_image_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2ee4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '6b86c32f-3e1d-4be7-bbd4-dd16443808b2'\n",
    "resource_group  = 'rg-amlclass-zbyw'\n",
    "workspace_name  = 'azureml-zbyw'\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='mos2_defect_detection_yolo_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbbe3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall configuration for the script to be run on the compute cluster\n",
    "config = ScriptRunConfig(source_directory='./deploy_yolo_training/',   ## folder in which the script is located\n",
    "                         script='training_on_aml.py',       ## script name\n",
    "                         compute_target='GPU-zbyw1',\n",
    "                         environment=yolov5_env)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eb48acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zbyw/MSE544_project'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "984a6f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ml.azure.com/runs/mos2_defect_detection_yolo_training_1748597031_4de6b9ff?wsid=/subscriptions/6b86c32f-3e1d-4be7-bbd4-dd16443808b2/resourcegroups/rg-amlclass-zbyw/workspaces/azureml-zbyw&tid=f6b6dd5b-f02f-441a-99a0-162ac5060bd2\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(config)\n",
    "aml_url = run.get_portal_url()\n",
    "print(aml_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a8a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
